# -*- coding: utf-8 -*-
"""DWClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zJMxUlGEai8Tg-CQIF3qEaug4z9ZOE6c
"""
import tensorflow as tf

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from tensorflow import feature_column
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler

training_data = 'merged/capture_246058.txt'
trained_model = 'batteryVoltage_local.h5'
plotdir = 'plots/BV'

#https://www.tensorflow.org/tutorials/structured_data/feature_columns
dataframe = pd.read_csv(training_data)

dataframe['target'] = dataframe['batteryvoltage'].apply(lambda x: int(x*10 - 12))
n_classes = dataframe['target'].nunique()
print('N_CLASSES:', n_classes)

dataframe.drop(columns = ['timestamp', 'time', 'diff_ms', 'temp', 'batt','engine_ON', 'batteryvoltage', 'speed_knots', 'lat', 'long'], inplace=True)

feature_cols = [col for col in list(dataframe.columns) if col!='target']
print('FEATURES: ', feature_cols)

scaler = MinMaxScaler()
dataframe[feature_cols] = scaler.fit_transform(dataframe[feature_cols])

train, test = train_test_split(dataframe, test_size=0.3)
train, val = train_test_split(train, test_size=0.3)
print(len(train), 'train examples')
print(len(val), 'validation examples')
print(len(test), 'test examples')

# A utility method to create a tf.data dataset from a Pandas Dataframe                                                                                                                                      
def df_to_dataset(dataframe, shuffle=True, batch_size=32):
  dataframe = dataframe.copy()
  labels = dataframe.pop(('target'))
  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))
  ds = ds.batch(batch_size)
  return ds

feature_columns = [feature_column.numeric_column(col) for col in list(dataframe.columns) if col!='target']

feature_layer = tf.keras.layers.DenseFeatures(feature_columns)

batch_size = 16
train_ds = df_to_dataset(train, batch_size=batch_size)
val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)
test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)

# metrics = [
#   tf.keras.metrics.Accuracy(name='accuracy'),
#   tf.keras.metrics.AUC(name='auc')]

model = tf.keras.Sequential([
  feature_layer,
  layers.Dense(128, activation='relu'),
  layers.Dropout(0.5),
  layers.Dense(128, activation='relu'),
  layers.Dense(n_classes, activation='softmax')
])

model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy'])

EPOCHS = 30
history = model.fit(train_ds,
                    validation_data=val_ds,
                    epochs=EPOCHS)

epochs = range(EPOCHS)

_ = plt.figure()
plt.title('Loss')
plt.plot(epochs, history.history['loss'], color='blue', label='Train')
plt.plot(epochs, history.history['val_loss'], color='orange', label='Val')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.savefig(os.path.join(plotdir, 'loss.png'))

_ = plt.figure()
plt.title('Accuracy')
plt.plot(epochs, history.history['accuracy'], color='blue', label='Train')
plt.plot(epochs, history.history['val_accuracy'], color='orange', label='Val')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig(os.path.join(plotdir, 'accuracy.png'))

# _ = plt.figure()
# plt.title('AUC')
# plt.plot(epochs, history.history['auc'], color='blue', label='Train')
# plt.plot(epochs, history.history['val_auc'], color='orange', label='Val')
# plt.xlabel('Epoch')
# plt.ylabel('AUC')
# plt.legend()
# plt.savefig(os.path.join(plotdir, 'auc.png'))

model.save(trained_model)
